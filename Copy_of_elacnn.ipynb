{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dA9TO0y_hxyM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIL5dbqEh7vz",
        "outputId": "722f4f73-2b06-4742-8b9f-882a321684d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras.optimizers import RMSprop\n",
        "from PIL import Image, ImageChops, ImageEnhance\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "def train_Ela_Model(dataset_path, lr, ep):\n",
        "    def convert_to_ela_image(path, quality):\n",
        "        filename = path\n",
        "        resaved_filename = filename.split('.')[0] + '.resaved.jpg'\n",
        "        im = Image.open(filename).convert('RGB')\n",
        "        im.save(resaved_filename, 'JPEG', quality=quality)\n",
        "        resaved_im = Image.open(resaved_filename)\n",
        "        ela_im = ImageChops.difference(im, resaved_im)\n",
        "        extrema = ela_im.getextrema()\n",
        "        max_diff = max([ex[1] for ex in extrema])\n",
        "        if max_diff == 0:\n",
        "            max_diff = 1\n",
        "        scale = 255.0 / max_diff\n",
        "\n",
        "        ela_im = ImageEnhance.Brightness(ela_im).enhance(scale)\n",
        "        return ela_im\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for class_folder in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_folder)\n",
        "        for image_name in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_name)\n",
        "            X.append(np.array(convert_to_ela_image(image_path, 90).resize((128, 128))) / 255.0)  # Removed flatten\n",
        "            label_encoder = LabelEncoder()\n",
        "            Y.append(label_encoder.fit_transform([class_folder]))  # Assuming class folders represent different classes\n",
        "\n",
        "    X = np.array(X)\n",
        "    Y = to_categorical(Y, num_classes=len(os.listdir(dataset_path)))\n",
        "    X = X.reshape(-1, 128, 128, 3)\n",
        "\n",
        "    X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1, random_state=5, shuffle=True)\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='valid', activation='relu', input_shape=(128, 128, 3)))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(5, 5), strides=(2, 2), padding='valid', activation='relu'))\n",
        "    model.add(MaxPool2D(pool_size=2, strides=None, padding='valid', data_format='channels_last'))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(256, activation=\"relu\"))\n",
        "    model.add(Dropout(0.50))\n",
        "    model.add(Dense(len(os.listdir(dataset_path)), activation=\"softmax\"))\n",
        "    model.summary()\n",
        "\n",
        "    optimizer = RMSprop(learning_rate=lr, rho=0.9, epsilon=1e-08)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    epochs = ep\n",
        "    batch_size = 5\n",
        "\n",
        "    history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, Y_val), verbose=2)\n",
        "\n",
        "    # Rest of your code for plotting and saving the model\n",
        "\n",
        "    return history  # Optionally, you might want to return the training history for further analysis\n",
        "\n",
        "# Example usage:\n",
        "dataset_path = '/content/drive/MyDrive/CASIA2.0_Groundtruth'\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "train_Ela_Model(dataset_path, learning_rate, num_epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k86z4rl6ixi8",
        "outputId": "05735576-fcae-43bf-b2f0-16e4aeb822a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 124, 124, 32)      2432      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 60, 60, 32)        25632     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 30, 30, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 30, 30, 32)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 28800)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               7373056   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7401377 (28.23 MB)\n",
            "Trainable params: 7401377 (28.23 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "924/924 - 274s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - 274s/epoch - 297ms/step\n",
            "Epoch 2/10\n",
            "924/924 - 280s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - 280s/epoch - 303ms/step\n",
            "Epoch 3/10\n",
            "924/924 - 273s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - 273s/epoch - 296ms/step\n",
            "Epoch 4/10\n",
            "924/924 - 280s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - 280s/epoch - 303ms/step\n",
            "Epoch 5/10\n",
            "924/924 - 274s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - 274s/epoch - 297ms/step\n",
            "Epoch 6/10\n",
            "924/924 - 272s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - 272s/epoch - 294ms/step\n",
            "Epoch 7/10\n",
            "924/924 - 279s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - 279s/epoch - 302ms/step\n",
            "Epoch 8/10\n",
            "924/924 - 273s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - 273s/epoch - 296ms/step\n",
            "Epoch 9/10\n",
            "924/924 - 276s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - 276s/epoch - 298ms/step\n",
            "Epoch 10/10\n",
            "924/924 - 278s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - 278s/epoch - 301ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d288ad0bc70>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ]
}