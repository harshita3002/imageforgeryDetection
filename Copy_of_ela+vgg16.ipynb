{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rov6jmIW5QPW"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import models, layers, optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from PIL import Image, ImageChops, ImageEnhance\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def convert_to_ela_image(path, quality):\n",
        "    filename = path\n",
        "    resaved_filename = filename.split('.')[0] + '.resaved.jpg'\n",
        "    im = Image.open(filename).convert('RGB')\n",
        "    im.save(resaved_filename, 'JPEG', quality=quality)\n",
        "    resaved_im = Image.open(resaved_filename)\n",
        "    ela_im = ImageChops.difference(im, resaved_im)\n",
        "    extrema = ela_im.getextrema()\n",
        "    max_diff = max([ex[1] for ex in extrema])\n",
        "    if max_diff == 0:\n",
        "        max_diff = 1\n",
        "    scale = 255.0 / max_diff\n",
        "\n",
        "    ela_im = ImageEnhance.Brightness(ela_im).enhance(scale)\n",
        "    return ela_im\n",
        "\n",
        "def read_and_process_data(dataset_path):\n",
        "    X = []\n",
        "    Y = []\n",
        "    for class_folder in ['Au', 'Tp']:\n",
        "        class_path = os.path.join(dataset_path, class_folder)\n",
        "\n",
        "        if not os.path.exists(class_path):\n",
        "            print(f\"Folder '{class_folder}' not found in '{dataset_path}'. Please check your folder structure.\")\n",
        "            return\n",
        "\n",
        "        for image_name in os.listdir(class_path):\n",
        "            if image_name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
        "                image_path = os.path.join(class_path, image_name)\n",
        "                ela_image = convert_to_ela_image(image_path, 90)\n",
        "                ela_array = np.array(ela_image.resize((224, 224))) / 255.0\n",
        "                X.append(ela_array)\n",
        "                label_encoder = LabelEncoder()\n",
        "                Y.append(label_encoder.fit_transform([class_folder]))\n",
        "\n",
        "    X = np.array(X)\n",
        "    Y = to_categorical(Y, num_classes=2)\n",
        "    X = X.reshape(-1, 224, 224, 3)\n",
        "\n",
        "    X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1, random_state=5, shuffle=True)\n",
        "\n",
        "    return X_train, X_val, Y_train, Y_val\n",
        "\n",
        "def create_vgg16_model(input_shape):\n",
        "    vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    model = models.Sequential()\n",
        "    model.add(vgg_conv)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1024, activation='relu'))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.Dense(2, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "def train_vgg16_model(dataset_path, lr, ep):\n",
        "    X_train, X_val, Y_train, Y_val = read_and_process_data(dataset_path)\n",
        "\n",
        "    input_shape = (224, 224, 3)\n",
        "    model = create_vgg16_model(input_shape)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizers.RMSprop(lr=lr),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    epochs = ep\n",
        "    batch_size = 20\n",
        "\n",
        "    checkpoint = ModelCheckpoint(\"vgg16_best_model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True,\n",
        "                                 mode='max')\n",
        "\n",
        "    history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs,\n",
        "                        validation_data=(X_val, Y_val), verbose=2, callbacks=[checkpoint])\n",
        "\n",
        "\n",
        "    return history\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/CASIA2.0_revised'\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "train_vgg16_model(dataset_path, learning_rate, num_epochs)\n"
      ]
    }
  ]
}